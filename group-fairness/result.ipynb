{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import metrics\n",
    "from load_data import *\n",
    "with open('summary/adult5.out','r') as f:\n",
    "    out = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = re.split('\\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hat can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1589f6b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1589f6830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n\n\n\n Done \n\n\n\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x157526830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x15752f050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1575348c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x15753a680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x157526830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x15752f050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1575348c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x15753a680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n\n\n\n Done \n\n\n\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1577c17a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1577c9560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1577cd320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1577d00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1577c17a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1577c9560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1577cd320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1577d00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n\n\n\n Done \n\n\n\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1592897a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x159290560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x159293320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x159290710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1592897a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x159290560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x159293320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x159290710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n\n\n\n Done \n\n\n\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x157526710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1589c2b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1584138c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x15812e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x157526710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1589c2b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1584138c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x15812e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n\n\n\n Done \n\n\n\n"
    }
   ],
   "source": [
    "result = []\n",
    "for e in out:\n",
    "    result.append(eval(e))\n",
    "\n",
    "for r in result:\n",
    "    dd_half, sdd, spdd = metrics.metrics(x_test, grouped_x_test, lr = r['lr'], epsilon = r['epsilon'],\\\n",
    "     wlr = r['wlr'], w_reg = r['w_reg'], seed = 1, l2_reg = 0)\n",
    "    r['dd-half'] = dd_half\n",
    "    r['sdd'] = sdd\n",
    "    r['spdd'] = spdd\n",
    "    print('\\n\\n\\n Done \\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "res = pd.DataFrame(result)\n",
    "result = res.loc[res['test gap-rms-gender']<0.09]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     epsilon      lr       wlr  w_reg  test-acc  test gap-rms-gender  \\\n88   0.00001  0.0001  0.000100   10.0  0.816805             0.085841   \n137  0.00010  0.0001  0.000100   10.0  0.816031             0.084388   \n0    0.00100  0.0001  0.000100   10.0  0.818463             0.086332   \n38   0.00001  0.0001  0.000010   60.0  0.818905             0.088471   \n108  0.00010  0.0001  0.000010   30.0  0.821117             0.087519   \n91   0.00010  0.0001  0.000010   40.0  0.824212             0.086720   \n7    0.00100  0.0001  0.001000   10.0  0.820343             0.084678   \n4    0.00010  0.0001  0.001000   10.0  0.814815             0.088061   \n82   0.00001  0.0001  0.001000   20.0  0.811498             0.081604   \n144  0.00001  0.0001  0.000100   20.0  0.813267             0.075493   \n147  0.00100  0.0001  0.000010   20.0  0.827197             0.086038   \n149  0.00010  0.0001  0.000100   20.0  0.813599             0.073573   \n27   0.00010  0.0001  0.000010   50.0  0.823881             0.082580   \n47   0.00001  0.0001  0.001000   30.0  0.810614             0.074339   \n69   0.00010  0.0001  0.000010   60.0  0.825981             0.082822   \n14   0.10000  0.0001  0.001000   20.0  0.805639             0.083482   \n148  0.00100  0.0001  0.000100   20.0  0.818795             0.081401   \n112  0.00100  0.0001  0.000005   30.0  0.839359             0.087891   \n59   0.00010  0.0001  0.001000   20.0  0.813156             0.078088   \n10   0.01000  0.0001  0.000005   10.0  0.835710             0.086235   \n134  0.10000  0.0001  0.001000   10.0  0.837369             0.081743   \n28   0.00001  0.0001  0.000100   30.0  0.810614             0.072901   \n132  0.00001  0.0001  0.000100   40.0  0.809287             0.072139   \n32   0.00010  0.0001  0.000100   30.0  0.810503             0.075646   \n16   0.00100  0.0001  0.001000   20.0  0.819348             0.086307   \n23   0.00001  0.0001  0.000100   50.0  0.807628             0.076514   \n114  0.00001  0.0001  0.001000   40.0  0.808402             0.072476   \n124  0.00010  0.0001  0.000100   40.0  0.808181             0.079151   \n109  0.00100  0.0001  0.000010   30.0  0.838474             0.079466   \n83   0.00001  0.0001  0.001000   50.0  0.799668             0.070464   \n96   0.01000  0.0001  0.000010   10.0  0.838364             0.081135   \n2    0.01000  0.0001  0.000100   10.0  0.840796             0.077729   \n140  0.00010  0.0001  0.000100   50.0  0.808181             0.084753   \n64   0.00001  0.0001  0.000100   60.0  0.804643             0.077151   \n55   0.00010  0.0001  0.001000   30.0  0.808845             0.075338   \n133  0.01000  0.0001  0.001000   10.0  0.839580             0.079266   \n34   0.00001  0.0001  0.001000   60.0  0.787839             0.062571   \n50   0.00100  0.0001  0.001000   30.0  0.821559             0.084399   \n136  0.10000  0.0001  0.000100   10.0  0.843560             0.079584   \n94   0.00010  0.0001  0.001000   40.0  0.808513             0.077821   \n35   0.00010  0.0001  0.000100   60.0  0.807518             0.081798   \n106  0.00010  0.0001  0.001000   50.0  0.807739             0.077809   \n135  0.00100  0.0001  0.000005   40.0  0.849751             0.068978   \n45   0.00010  0.0001  0.001000   60.0  0.810171             0.081525   \n122  0.01000  0.0001  0.000100   40.0  0.848314             0.071096   \n24   0.10000  0.0001  0.000100   20.0  0.846545             0.072455   \n131  0.00100  0.0001  0.000010   40.0  0.845992             0.067945   \n130  0.10000  0.0001  0.000010   10.0  0.849420             0.062424   \n25   0.01000  0.0001  0.000100   30.0  0.847098             0.068822   \n120  0.00100  0.0001  0.001000   50.0  0.839690             0.088232   \n12   0.01000  0.0001  0.001000   20.0  0.851741             0.061855   \n6    0.10000  0.0001  0.000005   10.0  0.852405             0.060146   \n57   0.00100  0.0001  0.000010   50.0  0.851631             0.065473   \n15   0.10000  0.0001  0.000001   10.0  0.852405             0.086359   \n40   0.00100  0.0001  0.000005   50.0  0.851520             0.055708   \n71   0.10000  0.0001  0.000100   30.0  0.850083             0.052802   \n73   0.01000  0.0001  0.000005   20.0  0.851189             0.052097   \n75   0.00100  0.0001  0.000010   60.0  0.850857             0.049085   \n102  0.01000  0.0001  0.000001   40.0  0.853400             0.078987   \n42   0.00100  0.0001  0.000005   60.0  0.851852             0.041035   \n146  0.01000  0.0001  0.000010   20.0  0.850857             0.040096   \n48   0.01000  0.0001  0.000001   50.0  0.852294             0.084284   \n66   0.01000  0.0001  0.000100   60.0  0.850967             0.040780   \n107  0.01000  0.0001  0.000100   20.0  0.850857             0.041694   \n89   0.01000  0.0001  0.000100   50.0  0.848425             0.034170   \n67   0.10000  0.0001  0.000005   20.0  0.851078             0.038395   \n142  0.10000  0.0001  0.000010   20.0  0.850304             0.036918   \n90   0.01000  0.0001  0.000005   30.0  0.849972             0.037761   \n58   0.00100  0.0001  0.001000   60.0  0.848314             0.073318   \n30   0.01000  0.0001  0.000001   60.0  0.850304             0.082617   \n77   0.10000  0.0001  0.000001   20.0  0.847429             0.064745   \n100  0.01000  0.0001  0.000010   30.0  0.843449             0.039332   \n138  0.01000  0.0001  0.000005   40.0  0.841128             0.039395   \n72   0.10000  0.0001  0.000005   30.0  0.839580             0.024648   \n92   0.10000  0.0001  0.000100   40.0  0.830846             0.034321   \n127  0.01000  0.0001  0.000010   40.0  0.831399             0.025526   \n63   0.10000  0.0001  0.000001   30.0  0.827640             0.066337   \n84   0.10000  0.0001  0.000005   40.0  0.826645             0.017081   \n53   0.01000  0.0001  0.000005   50.0  0.827640             0.024105   \n80   0.10000  0.0001  0.000010   30.0  0.825428             0.018242   \n126  0.10000  0.0001  0.000010   40.0  0.812935             0.015514   \n41   0.10000  0.0001  0.000005   50.0  0.811166             0.003489   \n36   0.01000  0.0001  0.000010   50.0  0.808402             0.002860   \n103  0.10000  0.0001  0.000001   40.0  0.806965             0.033661   \n21   0.10000  0.0001  0.000010   50.0  0.800884             0.001703   \n49   0.10000  0.0001  0.000005   60.0  0.797678             0.002312   \n29   0.10000  0.0001  0.000010   60.0  0.793256             0.000514   \n95   0.01000  0.0001  0.000010   60.0  0.791377             0.013069   \n46   0.01000  0.0001  0.000005   60.0  0.784743             0.023349   \n20   0.10000  0.0001  0.000001   50.0  0.784853             0.002009   \n31   0.10000  0.0001  0.000001   60.0  0.770702             0.004789   \n99   0.10000  0.0001  0.001000   40.0  0.267772             0.017547   \n119  0.10000  0.0001  0.000100   50.0  0.762852             0.067204   \n33   0.10000  0.0001  0.000100   60.0  0.758762             0.024889   \n116  0.10000  0.0001  0.001000   50.0  0.244555             0.000845   \n118  0.10000  0.0001  0.001000   60.0  0.243118             0.000000   \n\n     test gap-rms-race  test bal-acc   dd-half       sdd      spdd  \n88            0.050923      0.820640  0.445157  0.381111  1.659924  \n137           0.051727      0.820437  0.443287  0.349328  1.536813  \n0             0.047061      0.820037  0.434477  0.427329  1.883050  \n38            0.057088      0.819867  0.452860  0.323644  1.334595  \n108           0.051879      0.819475  0.437838  0.379292  1.635841  \n91            0.054674      0.819359  0.451940  0.286408  1.219459  \n7             0.048522      0.818655  0.434774  0.341556  1.519676  \n4             0.051250      0.818399  0.448357  0.377303  1.665190  \n82            0.047061      0.815745  0.413357  0.334668  1.416464  \n144           0.047208      0.815524  0.403288  0.322605  1.354777  \n147           0.049330      0.813923  0.422609  0.333262  1.473162  \n149           0.043923      0.813737  0.393291  0.325457  1.396078  \n27            0.054587      0.813584  0.423831  0.296991  1.228473  \n47            0.044899      0.812382  0.389417  0.332438  1.381016  \n69            0.049932      0.811885  0.411747  0.270118  1.140279  \n14            0.054972      0.811102  0.428583  0.090016  0.396273  \n148           0.048463      0.810842  0.392380  0.320282  1.398298  \n112           0.044635      0.810536  0.429993  0.403244  1.792159  \n59            0.043627      0.810358  0.391155  0.333290  1.414386  \n10            0.052050      0.810286  0.438133  0.433698  1.934389  \n134           0.049362      0.808295  0.421108  0.228681  1.030766  \n28            0.040386      0.808061  0.367299  0.303497  1.250346  \n132           0.036751      0.807802  0.346983  0.264593  1.093444  \n32            0.046006      0.807371  0.368436  0.281737  1.179450  \n16            0.046712      0.806577  0.387655  0.356423  1.542419  \n23            0.036510      0.806398  0.340357  0.283130  1.102691  \n114           0.041468      0.805365  0.353799  0.276796  1.139703  \n124           0.039638      0.805219  0.341563  0.306749  1.232188  \n109           0.043319      0.804858  0.387718  0.284185  1.209834  \n83            0.040767      0.804843  0.341097  0.250309  0.999109  \n96            0.049697      0.804631  0.416372  0.387809  1.725950  \n2             0.046661      0.804385  0.401577  0.367428  1.662496  \n140           0.044083      0.803985  0.339413  0.266746  1.030331  \n64            0.033036      0.803963  0.324751  0.238654  0.919546  \n55            0.050213      0.803806  0.368152  0.304647  1.260417  \n133           0.045887      0.803273  0.405488  0.378449  1.703963  \n34            0.046873      0.803202  0.350952  0.267108  1.012945  \n50            0.038683      0.803099  0.343725  0.322239  1.367040  \n136           0.063107      0.801581  0.421239  0.235125  1.057752  \n94            0.039880      0.801426  0.342644  0.246129  1.028491  \n35            0.042341      0.801231  0.332658  0.297837  1.164604  \n106           0.038848      0.800451  0.327050  0.283134  1.147077  \n135           0.039693      0.799343  0.385221  0.347302  1.514969  \n45            0.036484      0.799280  0.314372  0.290227  1.133806  \n122           0.058132      0.799011  0.406968  0.055284  0.256193  \n24            0.049755      0.795990  0.393603  0.190885  0.856959  \n131           0.036209      0.794545  0.357413  0.250993  1.107033  \n130           0.042861      0.792024  0.368910  0.351718  1.593339  \n25            0.051050      0.791880  0.392257  0.093853  0.434064  \n120           0.031938      0.789919  0.282933  0.231670  0.978265  \n12            0.056897      0.788465  0.382462  0.154061  0.691225  \n6             0.040378      0.786897  0.350587  0.331376  1.512967  \n57            0.033052      0.786540  0.333877  0.198972  0.859412  \n15            0.045375      0.783655  0.384602  0.393664  1.770542  \n40            0.045004      0.781991  0.345606  0.219205  0.982471  \n71            0.042502      0.777028  0.348133  0.023470  0.098934  \n73            0.030480      0.776833  0.323811  0.290028  1.290879  \n75            0.041539      0.766582  0.302515  0.270115  1.165766  \n102           0.049807      0.764094  0.340329  0.345650  1.555627  \n42            0.035006      0.760911  0.299827  0.333678  1.477135  \n146           0.029721      0.759636  0.286276  0.291545  1.319333  \n48            0.037614      0.749936  0.307468  0.361734  1.631643  \n66            0.021990      0.748134  0.277952  0.032441  0.142655  \n107           0.022750      0.748061  0.266132  0.163095  0.749554  \n89            0.019209      0.742750  0.266937  0.002434  0.011164  \n67            0.023377      0.742496  0.250508  0.295483  1.320772  \n142           0.018400      0.739515  0.246234  0.298220  1.362253  \n90            0.021935      0.737753  0.241860  0.231519  1.049984  \n58            0.015609      0.735731  0.212811  0.141483  0.641985  \n30            0.023087      0.733959  0.274617  0.274421  1.235933  \n77            0.023237      0.725732  0.255379  0.329612  1.499418  \n100           0.011425      0.708441  0.191374  0.243416  1.085349  \n138           0.014458      0.698727  0.172635  0.222124  1.010111  \n72            0.010203      0.694926  0.178963  0.147254  0.674671  \n92            0.015649      0.671253  0.145401  0.080284  0.351295  \n127           0.019220      0.666370  0.136445  0.154604  0.689416  \n63            0.008075      0.660337  0.174144  0.291506  1.323073  \n84            0.009976      0.657211  0.134772  0.175277  0.783816  \n53            0.004021      0.656942  0.126939  0.124486  0.573219  \n80            0.008536      0.653629  0.126201  0.218772  0.992800  \n126           0.021834      0.621762  0.103590  0.284082  1.297616  \n41            0.026953      0.617815  0.105714  0.165811  0.749370  \n36            0.012159      0.611205  0.092245  0.120234  0.553490  \n103           0.005683      0.605779  0.100749  0.215613  0.979509  \n21            0.011679      0.592656  0.077258  0.195423  0.898920  \n49            0.005287      0.586063  0.070137  0.206489  0.945709  \n29            0.006337      0.575270  0.059915  0.163112  0.749570  \n95            0.013648      0.572022  0.060052  0.086479  0.392676  \n46            0.008752      0.558071  0.039021  0.111226  0.507678  \n20            0.013279      0.557835  0.052967  0.140649  0.636591  \n31            0.005253      0.528576  0.023071  0.086059  0.382939  \n99            0.011452      0.515207  0.054302  0.097311  0.411967  \n119           0.014350      0.512741  0.012477  0.074704  0.330868  \n33            0.002185      0.503865  0.005731  0.020442  0.087996  \n116           0.000804      0.500950  0.003470  0.042054  0.184902  \n118           0.000000      0.500000  0.000000  0.077001  0.334925  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epsilon</th>\n      <th>lr</th>\n      <th>wlr</th>\n      <th>w_reg</th>\n      <th>test-acc</th>\n      <th>test gap-rms-gender</th>\n      <th>test gap-rms-race</th>\n      <th>test bal-acc</th>\n      <th>dd-half</th>\n      <th>sdd</th>\n      <th>spdd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>88</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>10.0</td>\n      <td>0.816805</td>\n      <td>0.085841</td>\n      <td>0.050923</td>\n      <td>0.820640</td>\n      <td>0.445157</td>\n      <td>0.381111</td>\n      <td>1.659924</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>10.0</td>\n      <td>0.816031</td>\n      <td>0.084388</td>\n      <td>0.051727</td>\n      <td>0.820437</td>\n      <td>0.443287</td>\n      <td>0.349328</td>\n      <td>1.536813</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>10.0</td>\n      <td>0.818463</td>\n      <td>0.086332</td>\n      <td>0.047061</td>\n      <td>0.820037</td>\n      <td>0.434477</td>\n      <td>0.427329</td>\n      <td>1.883050</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.818905</td>\n      <td>0.088471</td>\n      <td>0.057088</td>\n      <td>0.819867</td>\n      <td>0.452860</td>\n      <td>0.323644</td>\n      <td>1.334595</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>30.0</td>\n      <td>0.821117</td>\n      <td>0.087519</td>\n      <td>0.051879</td>\n      <td>0.819475</td>\n      <td>0.437838</td>\n      <td>0.379292</td>\n      <td>1.635841</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.824212</td>\n      <td>0.086720</td>\n      <td>0.054674</td>\n      <td>0.819359</td>\n      <td>0.451940</td>\n      <td>0.286408</td>\n      <td>1.219459</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>10.0</td>\n      <td>0.820343</td>\n      <td>0.084678</td>\n      <td>0.048522</td>\n      <td>0.818655</td>\n      <td>0.434774</td>\n      <td>0.341556</td>\n      <td>1.519676</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>10.0</td>\n      <td>0.814815</td>\n      <td>0.088061</td>\n      <td>0.051250</td>\n      <td>0.818399</td>\n      <td>0.448357</td>\n      <td>0.377303</td>\n      <td>1.665190</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>20.0</td>\n      <td>0.811498</td>\n      <td>0.081604</td>\n      <td>0.047061</td>\n      <td>0.815745</td>\n      <td>0.413357</td>\n      <td>0.334668</td>\n      <td>1.416464</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>20.0</td>\n      <td>0.813267</td>\n      <td>0.075493</td>\n      <td>0.047208</td>\n      <td>0.815524</td>\n      <td>0.403288</td>\n      <td>0.322605</td>\n      <td>1.354777</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>20.0</td>\n      <td>0.827197</td>\n      <td>0.086038</td>\n      <td>0.049330</td>\n      <td>0.813923</td>\n      <td>0.422609</td>\n      <td>0.333262</td>\n      <td>1.473162</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>20.0</td>\n      <td>0.813599</td>\n      <td>0.073573</td>\n      <td>0.043923</td>\n      <td>0.813737</td>\n      <td>0.393291</td>\n      <td>0.325457</td>\n      <td>1.396078</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.823881</td>\n      <td>0.082580</td>\n      <td>0.054587</td>\n      <td>0.813584</td>\n      <td>0.423831</td>\n      <td>0.296991</td>\n      <td>1.228473</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>30.0</td>\n      <td>0.810614</td>\n      <td>0.074339</td>\n      <td>0.044899</td>\n      <td>0.812382</td>\n      <td>0.389417</td>\n      <td>0.332438</td>\n      <td>1.381016</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.825981</td>\n      <td>0.082822</td>\n      <td>0.049932</td>\n      <td>0.811885</td>\n      <td>0.411747</td>\n      <td>0.270118</td>\n      <td>1.140279</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>20.0</td>\n      <td>0.805639</td>\n      <td>0.083482</td>\n      <td>0.054972</td>\n      <td>0.811102</td>\n      <td>0.428583</td>\n      <td>0.090016</td>\n      <td>0.396273</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>20.0</td>\n      <td>0.818795</td>\n      <td>0.081401</td>\n      <td>0.048463</td>\n      <td>0.810842</td>\n      <td>0.392380</td>\n      <td>0.320282</td>\n      <td>1.398298</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>30.0</td>\n      <td>0.839359</td>\n      <td>0.087891</td>\n      <td>0.044635</td>\n      <td>0.810536</td>\n      <td>0.429993</td>\n      <td>0.403244</td>\n      <td>1.792159</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>20.0</td>\n      <td>0.813156</td>\n      <td>0.078088</td>\n      <td>0.043627</td>\n      <td>0.810358</td>\n      <td>0.391155</td>\n      <td>0.333290</td>\n      <td>1.414386</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>10.0</td>\n      <td>0.835710</td>\n      <td>0.086235</td>\n      <td>0.052050</td>\n      <td>0.810286</td>\n      <td>0.438133</td>\n      <td>0.433698</td>\n      <td>1.934389</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>10.0</td>\n      <td>0.837369</td>\n      <td>0.081743</td>\n      <td>0.049362</td>\n      <td>0.808295</td>\n      <td>0.421108</td>\n      <td>0.228681</td>\n      <td>1.030766</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>30.0</td>\n      <td>0.810614</td>\n      <td>0.072901</td>\n      <td>0.040386</td>\n      <td>0.808061</td>\n      <td>0.367299</td>\n      <td>0.303497</td>\n      <td>1.250346</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>40.0</td>\n      <td>0.809287</td>\n      <td>0.072139</td>\n      <td>0.036751</td>\n      <td>0.807802</td>\n      <td>0.346983</td>\n      <td>0.264593</td>\n      <td>1.093444</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>30.0</td>\n      <td>0.810503</td>\n      <td>0.075646</td>\n      <td>0.046006</td>\n      <td>0.807371</td>\n      <td>0.368436</td>\n      <td>0.281737</td>\n      <td>1.179450</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>20.0</td>\n      <td>0.819348</td>\n      <td>0.086307</td>\n      <td>0.046712</td>\n      <td>0.806577</td>\n      <td>0.387655</td>\n      <td>0.356423</td>\n      <td>1.542419</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>50.0</td>\n      <td>0.807628</td>\n      <td>0.076514</td>\n      <td>0.036510</td>\n      <td>0.806398</td>\n      <td>0.340357</td>\n      <td>0.283130</td>\n      <td>1.102691</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>40.0</td>\n      <td>0.808402</td>\n      <td>0.072476</td>\n      <td>0.041468</td>\n      <td>0.805365</td>\n      <td>0.353799</td>\n      <td>0.276796</td>\n      <td>1.139703</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>40.0</td>\n      <td>0.808181</td>\n      <td>0.079151</td>\n      <td>0.039638</td>\n      <td>0.805219</td>\n      <td>0.341563</td>\n      <td>0.306749</td>\n      <td>1.232188</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>30.0</td>\n      <td>0.838474</td>\n      <td>0.079466</td>\n      <td>0.043319</td>\n      <td>0.804858</td>\n      <td>0.387718</td>\n      <td>0.284185</td>\n      <td>1.209834</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>50.0</td>\n      <td>0.799668</td>\n      <td>0.070464</td>\n      <td>0.040767</td>\n      <td>0.804843</td>\n      <td>0.341097</td>\n      <td>0.250309</td>\n      <td>0.999109</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>10.0</td>\n      <td>0.838364</td>\n      <td>0.081135</td>\n      <td>0.049697</td>\n      <td>0.804631</td>\n      <td>0.416372</td>\n      <td>0.387809</td>\n      <td>1.725950</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>10.0</td>\n      <td>0.840796</td>\n      <td>0.077729</td>\n      <td>0.046661</td>\n      <td>0.804385</td>\n      <td>0.401577</td>\n      <td>0.367428</td>\n      <td>1.662496</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>50.0</td>\n      <td>0.808181</td>\n      <td>0.084753</td>\n      <td>0.044083</td>\n      <td>0.803985</td>\n      <td>0.339413</td>\n      <td>0.266746</td>\n      <td>1.030331</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>60.0</td>\n      <td>0.804643</td>\n      <td>0.077151</td>\n      <td>0.033036</td>\n      <td>0.803963</td>\n      <td>0.324751</td>\n      <td>0.238654</td>\n      <td>0.919546</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>30.0</td>\n      <td>0.808845</td>\n      <td>0.075338</td>\n      <td>0.050213</td>\n      <td>0.803806</td>\n      <td>0.368152</td>\n      <td>0.304647</td>\n      <td>1.260417</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>10.0</td>\n      <td>0.839580</td>\n      <td>0.079266</td>\n      <td>0.045887</td>\n      <td>0.803273</td>\n      <td>0.405488</td>\n      <td>0.378449</td>\n      <td>1.703963</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>60.0</td>\n      <td>0.787839</td>\n      <td>0.062571</td>\n      <td>0.046873</td>\n      <td>0.803202</td>\n      <td>0.350952</td>\n      <td>0.267108</td>\n      <td>1.012945</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>30.0</td>\n      <td>0.821559</td>\n      <td>0.084399</td>\n      <td>0.038683</td>\n      <td>0.803099</td>\n      <td>0.343725</td>\n      <td>0.322239</td>\n      <td>1.367040</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>10.0</td>\n      <td>0.843560</td>\n      <td>0.079584</td>\n      <td>0.063107</td>\n      <td>0.801581</td>\n      <td>0.421239</td>\n      <td>0.235125</td>\n      <td>1.057752</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>40.0</td>\n      <td>0.808513</td>\n      <td>0.077821</td>\n      <td>0.039880</td>\n      <td>0.801426</td>\n      <td>0.342644</td>\n      <td>0.246129</td>\n      <td>1.028491</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>60.0</td>\n      <td>0.807518</td>\n      <td>0.081798</td>\n      <td>0.042341</td>\n      <td>0.801231</td>\n      <td>0.332658</td>\n      <td>0.297837</td>\n      <td>1.164604</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>50.0</td>\n      <td>0.807739</td>\n      <td>0.077809</td>\n      <td>0.038848</td>\n      <td>0.800451</td>\n      <td>0.327050</td>\n      <td>0.283134</td>\n      <td>1.147077</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>40.0</td>\n      <td>0.849751</td>\n      <td>0.068978</td>\n      <td>0.039693</td>\n      <td>0.799343</td>\n      <td>0.385221</td>\n      <td>0.347302</td>\n      <td>1.514969</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.00010</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>60.0</td>\n      <td>0.810171</td>\n      <td>0.081525</td>\n      <td>0.036484</td>\n      <td>0.799280</td>\n      <td>0.314372</td>\n      <td>0.290227</td>\n      <td>1.133806</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>40.0</td>\n      <td>0.848314</td>\n      <td>0.071096</td>\n      <td>0.058132</td>\n      <td>0.799011</td>\n      <td>0.406968</td>\n      <td>0.055284</td>\n      <td>0.256193</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>20.0</td>\n      <td>0.846545</td>\n      <td>0.072455</td>\n      <td>0.049755</td>\n      <td>0.795990</td>\n      <td>0.393603</td>\n      <td>0.190885</td>\n      <td>0.856959</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.845992</td>\n      <td>0.067945</td>\n      <td>0.036209</td>\n      <td>0.794545</td>\n      <td>0.357413</td>\n      <td>0.250993</td>\n      <td>1.107033</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>10.0</td>\n      <td>0.849420</td>\n      <td>0.062424</td>\n      <td>0.042861</td>\n      <td>0.792024</td>\n      <td>0.368910</td>\n      <td>0.351718</td>\n      <td>1.593339</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>30.0</td>\n      <td>0.847098</td>\n      <td>0.068822</td>\n      <td>0.051050</td>\n      <td>0.791880</td>\n      <td>0.392257</td>\n      <td>0.093853</td>\n      <td>0.434064</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>50.0</td>\n      <td>0.839690</td>\n      <td>0.088232</td>\n      <td>0.031938</td>\n      <td>0.789919</td>\n      <td>0.282933</td>\n      <td>0.231670</td>\n      <td>0.978265</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>20.0</td>\n      <td>0.851741</td>\n      <td>0.061855</td>\n      <td>0.056897</td>\n      <td>0.788465</td>\n      <td>0.382462</td>\n      <td>0.154061</td>\n      <td>0.691225</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>10.0</td>\n      <td>0.852405</td>\n      <td>0.060146</td>\n      <td>0.040378</td>\n      <td>0.786897</td>\n      <td>0.350587</td>\n      <td>0.331376</td>\n      <td>1.512967</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.851631</td>\n      <td>0.065473</td>\n      <td>0.033052</td>\n      <td>0.786540</td>\n      <td>0.333877</td>\n      <td>0.198972</td>\n      <td>0.859412</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>10.0</td>\n      <td>0.852405</td>\n      <td>0.086359</td>\n      <td>0.045375</td>\n      <td>0.783655</td>\n      <td>0.384602</td>\n      <td>0.393664</td>\n      <td>1.770542</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>50.0</td>\n      <td>0.851520</td>\n      <td>0.055708</td>\n      <td>0.045004</td>\n      <td>0.781991</td>\n      <td>0.345606</td>\n      <td>0.219205</td>\n      <td>0.982471</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>30.0</td>\n      <td>0.850083</td>\n      <td>0.052802</td>\n      <td>0.042502</td>\n      <td>0.777028</td>\n      <td>0.348133</td>\n      <td>0.023470</td>\n      <td>0.098934</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>20.0</td>\n      <td>0.851189</td>\n      <td>0.052097</td>\n      <td>0.030480</td>\n      <td>0.776833</td>\n      <td>0.323811</td>\n      <td>0.290028</td>\n      <td>1.290879</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.850857</td>\n      <td>0.049085</td>\n      <td>0.041539</td>\n      <td>0.766582</td>\n      <td>0.302515</td>\n      <td>0.270115</td>\n      <td>1.165766</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>40.0</td>\n      <td>0.853400</td>\n      <td>0.078987</td>\n      <td>0.049807</td>\n      <td>0.764094</td>\n      <td>0.340329</td>\n      <td>0.345650</td>\n      <td>1.555627</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>60.0</td>\n      <td>0.851852</td>\n      <td>0.041035</td>\n      <td>0.035006</td>\n      <td>0.760911</td>\n      <td>0.299827</td>\n      <td>0.333678</td>\n      <td>1.477135</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>20.0</td>\n      <td>0.850857</td>\n      <td>0.040096</td>\n      <td>0.029721</td>\n      <td>0.759636</td>\n      <td>0.286276</td>\n      <td>0.291545</td>\n      <td>1.319333</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>50.0</td>\n      <td>0.852294</td>\n      <td>0.084284</td>\n      <td>0.037614</td>\n      <td>0.749936</td>\n      <td>0.307468</td>\n      <td>0.361734</td>\n      <td>1.631643</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>60.0</td>\n      <td>0.850967</td>\n      <td>0.040780</td>\n      <td>0.021990</td>\n      <td>0.748134</td>\n      <td>0.277952</td>\n      <td>0.032441</td>\n      <td>0.142655</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>20.0</td>\n      <td>0.850857</td>\n      <td>0.041694</td>\n      <td>0.022750</td>\n      <td>0.748061</td>\n      <td>0.266132</td>\n      <td>0.163095</td>\n      <td>0.749554</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>50.0</td>\n      <td>0.848425</td>\n      <td>0.034170</td>\n      <td>0.019209</td>\n      <td>0.742750</td>\n      <td>0.266937</td>\n      <td>0.002434</td>\n      <td>0.011164</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>20.0</td>\n      <td>0.851078</td>\n      <td>0.038395</td>\n      <td>0.023377</td>\n      <td>0.742496</td>\n      <td>0.250508</td>\n      <td>0.295483</td>\n      <td>1.320772</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>20.0</td>\n      <td>0.850304</td>\n      <td>0.036918</td>\n      <td>0.018400</td>\n      <td>0.739515</td>\n      <td>0.246234</td>\n      <td>0.298220</td>\n      <td>1.362253</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>30.0</td>\n      <td>0.849972</td>\n      <td>0.037761</td>\n      <td>0.021935</td>\n      <td>0.737753</td>\n      <td>0.241860</td>\n      <td>0.231519</td>\n      <td>1.049984</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>60.0</td>\n      <td>0.848314</td>\n      <td>0.073318</td>\n      <td>0.015609</td>\n      <td>0.735731</td>\n      <td>0.212811</td>\n      <td>0.141483</td>\n      <td>0.641985</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>60.0</td>\n      <td>0.850304</td>\n      <td>0.082617</td>\n      <td>0.023087</td>\n      <td>0.733959</td>\n      <td>0.274617</td>\n      <td>0.274421</td>\n      <td>1.235933</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>20.0</td>\n      <td>0.847429</td>\n      <td>0.064745</td>\n      <td>0.023237</td>\n      <td>0.725732</td>\n      <td>0.255379</td>\n      <td>0.329612</td>\n      <td>1.499418</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>30.0</td>\n      <td>0.843449</td>\n      <td>0.039332</td>\n      <td>0.011425</td>\n      <td>0.708441</td>\n      <td>0.191374</td>\n      <td>0.243416</td>\n      <td>1.085349</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>40.0</td>\n      <td>0.841128</td>\n      <td>0.039395</td>\n      <td>0.014458</td>\n      <td>0.698727</td>\n      <td>0.172635</td>\n      <td>0.222124</td>\n      <td>1.010111</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>30.0</td>\n      <td>0.839580</td>\n      <td>0.024648</td>\n      <td>0.010203</td>\n      <td>0.694926</td>\n      <td>0.178963</td>\n      <td>0.147254</td>\n      <td>0.674671</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>40.0</td>\n      <td>0.830846</td>\n      <td>0.034321</td>\n      <td>0.015649</td>\n      <td>0.671253</td>\n      <td>0.145401</td>\n      <td>0.080284</td>\n      <td>0.351295</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.831399</td>\n      <td>0.025526</td>\n      <td>0.019220</td>\n      <td>0.666370</td>\n      <td>0.136445</td>\n      <td>0.154604</td>\n      <td>0.689416</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>30.0</td>\n      <td>0.827640</td>\n      <td>0.066337</td>\n      <td>0.008075</td>\n      <td>0.660337</td>\n      <td>0.174144</td>\n      <td>0.291506</td>\n      <td>1.323073</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>40.0</td>\n      <td>0.826645</td>\n      <td>0.017081</td>\n      <td>0.009976</td>\n      <td>0.657211</td>\n      <td>0.134772</td>\n      <td>0.175277</td>\n      <td>0.783816</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>50.0</td>\n      <td>0.827640</td>\n      <td>0.024105</td>\n      <td>0.004021</td>\n      <td>0.656942</td>\n      <td>0.126939</td>\n      <td>0.124486</td>\n      <td>0.573219</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>30.0</td>\n      <td>0.825428</td>\n      <td>0.018242</td>\n      <td>0.008536</td>\n      <td>0.653629</td>\n      <td>0.126201</td>\n      <td>0.218772</td>\n      <td>0.992800</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.812935</td>\n      <td>0.015514</td>\n      <td>0.021834</td>\n      <td>0.621762</td>\n      <td>0.103590</td>\n      <td>0.284082</td>\n      <td>1.297616</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>50.0</td>\n      <td>0.811166</td>\n      <td>0.003489</td>\n      <td>0.026953</td>\n      <td>0.617815</td>\n      <td>0.105714</td>\n      <td>0.165811</td>\n      <td>0.749370</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.808402</td>\n      <td>0.002860</td>\n      <td>0.012159</td>\n      <td>0.611205</td>\n      <td>0.092245</td>\n      <td>0.120234</td>\n      <td>0.553490</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>40.0</td>\n      <td>0.806965</td>\n      <td>0.033661</td>\n      <td>0.005683</td>\n      <td>0.605779</td>\n      <td>0.100749</td>\n      <td>0.215613</td>\n      <td>0.979509</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.800884</td>\n      <td>0.001703</td>\n      <td>0.011679</td>\n      <td>0.592656</td>\n      <td>0.077258</td>\n      <td>0.195423</td>\n      <td>0.898920</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>60.0</td>\n      <td>0.797678</td>\n      <td>0.002312</td>\n      <td>0.005287</td>\n      <td>0.586063</td>\n      <td>0.070137</td>\n      <td>0.206489</td>\n      <td>0.945709</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.793256</td>\n      <td>0.000514</td>\n      <td>0.006337</td>\n      <td>0.575270</td>\n      <td>0.059915</td>\n      <td>0.163112</td>\n      <td>0.749570</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.791377</td>\n      <td>0.013069</td>\n      <td>0.013648</td>\n      <td>0.572022</td>\n      <td>0.060052</td>\n      <td>0.086479</td>\n      <td>0.392676</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>60.0</td>\n      <td>0.784743</td>\n      <td>0.023349</td>\n      <td>0.008752</td>\n      <td>0.558071</td>\n      <td>0.039021</td>\n      <td>0.111226</td>\n      <td>0.507678</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>50.0</td>\n      <td>0.784853</td>\n      <td>0.002009</td>\n      <td>0.013279</td>\n      <td>0.557835</td>\n      <td>0.052967</td>\n      <td>0.140649</td>\n      <td>0.636591</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>60.0</td>\n      <td>0.770702</td>\n      <td>0.004789</td>\n      <td>0.005253</td>\n      <td>0.528576</td>\n      <td>0.023071</td>\n      <td>0.086059</td>\n      <td>0.382939</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>40.0</td>\n      <td>0.267772</td>\n      <td>0.017547</td>\n      <td>0.011452</td>\n      <td>0.515207</td>\n      <td>0.054302</td>\n      <td>0.097311</td>\n      <td>0.411967</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>50.0</td>\n      <td>0.762852</td>\n      <td>0.067204</td>\n      <td>0.014350</td>\n      <td>0.512741</td>\n      <td>0.012477</td>\n      <td>0.074704</td>\n      <td>0.330868</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>60.0</td>\n      <td>0.758762</td>\n      <td>0.024889</td>\n      <td>0.002185</td>\n      <td>0.503865</td>\n      <td>0.005731</td>\n      <td>0.020442</td>\n      <td>0.087996</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>50.0</td>\n      <td>0.244555</td>\n      <td>0.000845</td>\n      <td>0.000804</td>\n      <td>0.500950</td>\n      <td>0.003470</td>\n      <td>0.042054</td>\n      <td>0.184902</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>60.0</td>\n      <td>0.243118</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.077001</td>\n      <td>0.334925</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "result.sort_values(by='test bal-acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit48aa32fa6dba4f1bbd692e320b15fd93",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}