{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import metrics\n",
    "from load_data import *\n",
    "with open('summary/adult5.out','r') as f:\n",
    "    out = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = re.split('\\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "erimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x161757050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x16174fef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1606325f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x160628680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x16063cd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x160640b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1606325f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x160628680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x16063cd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x160640b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1619d4170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1619d4ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1619d9cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1619dfa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1619d4170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1619d4ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1619d9cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1619dfa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1620eec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1620f49e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1620f47a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1620ee7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1620eec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1620f49e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1620f47a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1620ee7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1619c6d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x16060b170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1617157a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x1611a18c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1619c6d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x16060b170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1617157a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1611a18c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
    }
   ],
   "source": [
    "result = []\n",
    "for e in out:\n",
    "    result.append(eval(e))\n",
    "\n",
    "for r in result:\n",
    "    dd_half, sdd, spdd = metrics.metrics(x_test, grouped_x_test, lr = r['lr'], epsilon = r['epsilon'],\\\n",
    "     wlr = r['wlr'], w_reg = r['w_reg'], seed = 1, l2_reg = 0)\n",
    "    r['dd-half'] = dd_half\n",
    "    r['sdd'] = sdd\n",
    "    r['spdd'] = spdd\n",
    "    print('\\n\\n\\n Done \\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "res = pd.DataFrame(result)\n",
    "result = res.loc[res['test gap-rms-gender']<0.07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     epsilon      lr       wlr  w_reg  test-acc  test gap-rms-gender  \\\n34   0.00001  0.0001  0.001000   60.0  0.787839             0.062571   \n135  0.00100  0.0001  0.000005   40.0  0.849751             0.068978   \n131  0.00100  0.0001  0.000010   40.0  0.845992             0.067945   \n130  0.10000  0.0001  0.000010   10.0  0.849420             0.062424   \n25   0.01000  0.0001  0.000100   30.0  0.847098             0.068822   \n12   0.01000  0.0001  0.001000   20.0  0.851741             0.061855   \n6    0.10000  0.0001  0.000005   10.0  0.852405             0.060146   \n57   0.00100  0.0001  0.000010   50.0  0.851631             0.065473   \n40   0.00100  0.0001  0.000005   50.0  0.851520             0.055708   \n71   0.10000  0.0001  0.000100   30.0  0.850083             0.052802   \n73   0.01000  0.0001  0.000005   20.0  0.851189             0.052097   \n75   0.00100  0.0001  0.000010   60.0  0.850857             0.049085   \n42   0.00100  0.0001  0.000005   60.0  0.851852             0.041035   \n146  0.01000  0.0001  0.000010   20.0  0.850857             0.040096   \n66   0.01000  0.0001  0.000100   60.0  0.850967             0.040780   \n107  0.01000  0.0001  0.000100   20.0  0.850857             0.041694   \n89   0.01000  0.0001  0.000100   50.0  0.848425             0.034170   \n67   0.10000  0.0001  0.000005   20.0  0.851078             0.038395   \n142  0.10000  0.0001  0.000010   20.0  0.850304             0.036918   \n90   0.01000  0.0001  0.000005   30.0  0.849972             0.037761   \n77   0.10000  0.0001  0.000001   20.0  0.847429             0.064745   \n100  0.01000  0.0001  0.000010   30.0  0.843449             0.039332   \n138  0.01000  0.0001  0.000005   40.0  0.841128             0.039395   \n72   0.10000  0.0001  0.000005   30.0  0.839580             0.024648   \n92   0.10000  0.0001  0.000100   40.0  0.830846             0.034321   \n127  0.01000  0.0001  0.000010   40.0  0.831399             0.025526   \n63   0.10000  0.0001  0.000001   30.0  0.827640             0.066337   \n84   0.10000  0.0001  0.000005   40.0  0.826645             0.017081   \n53   0.01000  0.0001  0.000005   50.0  0.827640             0.024105   \n80   0.10000  0.0001  0.000010   30.0  0.825428             0.018242   \n126  0.10000  0.0001  0.000010   40.0  0.812935             0.015514   \n41   0.10000  0.0001  0.000005   50.0  0.811166             0.003489   \n36   0.01000  0.0001  0.000010   50.0  0.808402             0.002860   \n103  0.10000  0.0001  0.000001   40.0  0.806965             0.033661   \n21   0.10000  0.0001  0.000010   50.0  0.800884             0.001703   \n49   0.10000  0.0001  0.000005   60.0  0.797678             0.002312   \n29   0.10000  0.0001  0.000010   60.0  0.793256             0.000514   \n95   0.01000  0.0001  0.000010   60.0  0.791377             0.013069   \n46   0.01000  0.0001  0.000005   60.0  0.784743             0.023349   \n20   0.10000  0.0001  0.000001   50.0  0.784853             0.002009   \n31   0.10000  0.0001  0.000001   60.0  0.770702             0.004789   \n99   0.10000  0.0001  0.001000   40.0  0.267772             0.017547   \n119  0.10000  0.0001  0.000100   50.0  0.762852             0.067204   \n33   0.10000  0.0001  0.000100   60.0  0.758762             0.024889   \n116  0.10000  0.0001  0.001000   50.0  0.244555             0.000845   \n118  0.10000  0.0001  0.001000   60.0  0.243118             0.000000   \n\n     test gap-rms-race  test bal-acc   dd-half       sdd      spdd  \n34            0.046873      0.803202  0.350952  0.267108  1.012945  \n135           0.039693      0.799343  0.385221  0.347302  1.514969  \n131           0.036209      0.794545  0.357413  0.250993  1.107033  \n130           0.042861      0.792024  0.368910  0.351718  1.593339  \n25            0.051050      0.791880  0.392257  0.093853  0.434064  \n12            0.056897      0.788465  0.382462  0.154061  0.691225  \n6             0.040378      0.786897  0.350587  0.331376  1.512967  \n57            0.033052      0.786540  0.333877  0.198972  0.859412  \n40            0.045004      0.781991  0.345606  0.219205  0.982471  \n71            0.042502      0.777028  0.348133  0.023470  0.098934  \n73            0.030480      0.776833  0.323811  0.290028  1.290879  \n75            0.041539      0.766582  0.302515  0.270115  1.165766  \n42            0.035006      0.760911  0.299827  0.333678  1.477135  \n146           0.029721      0.759636  0.286276  0.291545  1.319333  \n66            0.021990      0.748134  0.277952  0.032441  0.142655  \n107           0.022750      0.748061  0.266132  0.163095  0.749554  \n89            0.019209      0.742750  0.266937  0.002434  0.011164  \n67            0.023377      0.742496  0.250508  0.295483  1.320772  \n142           0.018400      0.739515  0.246234  0.298220  1.362253  \n90            0.021935      0.737753  0.241860  0.231519  1.049984  \n77            0.023237      0.725732  0.255379  0.329612  1.499418  \n100           0.011425      0.708441  0.191374  0.243416  1.085349  \n138           0.014458      0.698727  0.172635  0.222124  1.010111  \n72            0.010203      0.694926  0.178963  0.147254  0.674671  \n92            0.015649      0.671253  0.145401  0.080284  0.351295  \n127           0.019220      0.666370  0.136445  0.154604  0.689416  \n63            0.008075      0.660337  0.174144  0.291506  1.323073  \n84            0.009976      0.657211  0.134772  0.175277  0.783816  \n53            0.004021      0.656942  0.126939  0.124486  0.573219  \n80            0.008536      0.653629  0.126201  0.218772  0.992800  \n126           0.021834      0.621762  0.103590  0.284082  1.297616  \n41            0.026953      0.617815  0.105714  0.165811  0.749370  \n36            0.012159      0.611205  0.092245  0.120234  0.553490  \n103           0.005683      0.605779  0.100749  0.215613  0.979509  \n21            0.011679      0.592656  0.077258  0.195423  0.898920  \n49            0.005287      0.586063  0.070137  0.206489  0.945709  \n29            0.006337      0.575270  0.059915  0.163112  0.749570  \n95            0.013648      0.572022  0.060052  0.086479  0.392676  \n46            0.008752      0.558071  0.039021  0.111226  0.507678  \n20            0.013279      0.557835  0.052967  0.140649  0.636591  \n31            0.005253      0.528576  0.023071  0.086059  0.382939  \n99            0.011452      0.515207  0.054302  0.097311  0.411967  \n119           0.014350      0.512741  0.012477  0.074704  0.330868  \n33            0.002185      0.503865  0.005731  0.020442  0.087996  \n116           0.000804      0.500950  0.003470  0.042054  0.184902  \n118           0.000000      0.500000  0.000000  0.077001  0.334925  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epsilon</th>\n      <th>lr</th>\n      <th>wlr</th>\n      <th>w_reg</th>\n      <th>test-acc</th>\n      <th>test gap-rms-gender</th>\n      <th>test gap-rms-race</th>\n      <th>test bal-acc</th>\n      <th>dd-half</th>\n      <th>sdd</th>\n      <th>spdd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34</th>\n      <td>0.00001</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>60.0</td>\n      <td>0.787839</td>\n      <td>0.062571</td>\n      <td>0.046873</td>\n      <td>0.803202</td>\n      <td>0.350952</td>\n      <td>0.267108</td>\n      <td>1.012945</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>40.0</td>\n      <td>0.849751</td>\n      <td>0.068978</td>\n      <td>0.039693</td>\n      <td>0.799343</td>\n      <td>0.385221</td>\n      <td>0.347302</td>\n      <td>1.514969</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.845992</td>\n      <td>0.067945</td>\n      <td>0.036209</td>\n      <td>0.794545</td>\n      <td>0.357413</td>\n      <td>0.250993</td>\n      <td>1.107033</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>10.0</td>\n      <td>0.849420</td>\n      <td>0.062424</td>\n      <td>0.042861</td>\n      <td>0.792024</td>\n      <td>0.368910</td>\n      <td>0.351718</td>\n      <td>1.593339</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>30.0</td>\n      <td>0.847098</td>\n      <td>0.068822</td>\n      <td>0.051050</td>\n      <td>0.791880</td>\n      <td>0.392257</td>\n      <td>0.093853</td>\n      <td>0.434064</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>20.0</td>\n      <td>0.851741</td>\n      <td>0.061855</td>\n      <td>0.056897</td>\n      <td>0.788465</td>\n      <td>0.382462</td>\n      <td>0.154061</td>\n      <td>0.691225</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>10.0</td>\n      <td>0.852405</td>\n      <td>0.060146</td>\n      <td>0.040378</td>\n      <td>0.786897</td>\n      <td>0.350587</td>\n      <td>0.331376</td>\n      <td>1.512967</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.851631</td>\n      <td>0.065473</td>\n      <td>0.033052</td>\n      <td>0.786540</td>\n      <td>0.333877</td>\n      <td>0.198972</td>\n      <td>0.859412</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>50.0</td>\n      <td>0.851520</td>\n      <td>0.055708</td>\n      <td>0.045004</td>\n      <td>0.781991</td>\n      <td>0.345606</td>\n      <td>0.219205</td>\n      <td>0.982471</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>30.0</td>\n      <td>0.850083</td>\n      <td>0.052802</td>\n      <td>0.042502</td>\n      <td>0.777028</td>\n      <td>0.348133</td>\n      <td>0.023470</td>\n      <td>0.098934</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>20.0</td>\n      <td>0.851189</td>\n      <td>0.052097</td>\n      <td>0.030480</td>\n      <td>0.776833</td>\n      <td>0.323811</td>\n      <td>0.290028</td>\n      <td>1.290879</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.850857</td>\n      <td>0.049085</td>\n      <td>0.041539</td>\n      <td>0.766582</td>\n      <td>0.302515</td>\n      <td>0.270115</td>\n      <td>1.165766</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.00100</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>60.0</td>\n      <td>0.851852</td>\n      <td>0.041035</td>\n      <td>0.035006</td>\n      <td>0.760911</td>\n      <td>0.299827</td>\n      <td>0.333678</td>\n      <td>1.477135</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>20.0</td>\n      <td>0.850857</td>\n      <td>0.040096</td>\n      <td>0.029721</td>\n      <td>0.759636</td>\n      <td>0.286276</td>\n      <td>0.291545</td>\n      <td>1.319333</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>60.0</td>\n      <td>0.850967</td>\n      <td>0.040780</td>\n      <td>0.021990</td>\n      <td>0.748134</td>\n      <td>0.277952</td>\n      <td>0.032441</td>\n      <td>0.142655</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>20.0</td>\n      <td>0.850857</td>\n      <td>0.041694</td>\n      <td>0.022750</td>\n      <td>0.748061</td>\n      <td>0.266132</td>\n      <td>0.163095</td>\n      <td>0.749554</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>50.0</td>\n      <td>0.848425</td>\n      <td>0.034170</td>\n      <td>0.019209</td>\n      <td>0.742750</td>\n      <td>0.266937</td>\n      <td>0.002434</td>\n      <td>0.011164</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>20.0</td>\n      <td>0.851078</td>\n      <td>0.038395</td>\n      <td>0.023377</td>\n      <td>0.742496</td>\n      <td>0.250508</td>\n      <td>0.295483</td>\n      <td>1.320772</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>20.0</td>\n      <td>0.850304</td>\n      <td>0.036918</td>\n      <td>0.018400</td>\n      <td>0.739515</td>\n      <td>0.246234</td>\n      <td>0.298220</td>\n      <td>1.362253</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>30.0</td>\n      <td>0.849972</td>\n      <td>0.037761</td>\n      <td>0.021935</td>\n      <td>0.737753</td>\n      <td>0.241860</td>\n      <td>0.231519</td>\n      <td>1.049984</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>20.0</td>\n      <td>0.847429</td>\n      <td>0.064745</td>\n      <td>0.023237</td>\n      <td>0.725732</td>\n      <td>0.255379</td>\n      <td>0.329612</td>\n      <td>1.499418</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>30.0</td>\n      <td>0.843449</td>\n      <td>0.039332</td>\n      <td>0.011425</td>\n      <td>0.708441</td>\n      <td>0.191374</td>\n      <td>0.243416</td>\n      <td>1.085349</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>40.0</td>\n      <td>0.841128</td>\n      <td>0.039395</td>\n      <td>0.014458</td>\n      <td>0.698727</td>\n      <td>0.172635</td>\n      <td>0.222124</td>\n      <td>1.010111</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>30.0</td>\n      <td>0.839580</td>\n      <td>0.024648</td>\n      <td>0.010203</td>\n      <td>0.694926</td>\n      <td>0.178963</td>\n      <td>0.147254</td>\n      <td>0.674671</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>40.0</td>\n      <td>0.830846</td>\n      <td>0.034321</td>\n      <td>0.015649</td>\n      <td>0.671253</td>\n      <td>0.145401</td>\n      <td>0.080284</td>\n      <td>0.351295</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.831399</td>\n      <td>0.025526</td>\n      <td>0.019220</td>\n      <td>0.666370</td>\n      <td>0.136445</td>\n      <td>0.154604</td>\n      <td>0.689416</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>30.0</td>\n      <td>0.827640</td>\n      <td>0.066337</td>\n      <td>0.008075</td>\n      <td>0.660337</td>\n      <td>0.174144</td>\n      <td>0.291506</td>\n      <td>1.323073</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>40.0</td>\n      <td>0.826645</td>\n      <td>0.017081</td>\n      <td>0.009976</td>\n      <td>0.657211</td>\n      <td>0.134772</td>\n      <td>0.175277</td>\n      <td>0.783816</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>50.0</td>\n      <td>0.827640</td>\n      <td>0.024105</td>\n      <td>0.004021</td>\n      <td>0.656942</td>\n      <td>0.126939</td>\n      <td>0.124486</td>\n      <td>0.573219</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>30.0</td>\n      <td>0.825428</td>\n      <td>0.018242</td>\n      <td>0.008536</td>\n      <td>0.653629</td>\n      <td>0.126201</td>\n      <td>0.218772</td>\n      <td>0.992800</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>40.0</td>\n      <td>0.812935</td>\n      <td>0.015514</td>\n      <td>0.021834</td>\n      <td>0.621762</td>\n      <td>0.103590</td>\n      <td>0.284082</td>\n      <td>1.297616</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>50.0</td>\n      <td>0.811166</td>\n      <td>0.003489</td>\n      <td>0.026953</td>\n      <td>0.617815</td>\n      <td>0.105714</td>\n      <td>0.165811</td>\n      <td>0.749370</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.808402</td>\n      <td>0.002860</td>\n      <td>0.012159</td>\n      <td>0.611205</td>\n      <td>0.092245</td>\n      <td>0.120234</td>\n      <td>0.553490</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>40.0</td>\n      <td>0.806965</td>\n      <td>0.033661</td>\n      <td>0.005683</td>\n      <td>0.605779</td>\n      <td>0.100749</td>\n      <td>0.215613</td>\n      <td>0.979509</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>50.0</td>\n      <td>0.800884</td>\n      <td>0.001703</td>\n      <td>0.011679</td>\n      <td>0.592656</td>\n      <td>0.077258</td>\n      <td>0.195423</td>\n      <td>0.898920</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>60.0</td>\n      <td>0.797678</td>\n      <td>0.002312</td>\n      <td>0.005287</td>\n      <td>0.586063</td>\n      <td>0.070137</td>\n      <td>0.206489</td>\n      <td>0.945709</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.793256</td>\n      <td>0.000514</td>\n      <td>0.006337</td>\n      <td>0.575270</td>\n      <td>0.059915</td>\n      <td>0.163112</td>\n      <td>0.749570</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000010</td>\n      <td>60.0</td>\n      <td>0.791377</td>\n      <td>0.013069</td>\n      <td>0.013648</td>\n      <td>0.572022</td>\n      <td>0.060052</td>\n      <td>0.086479</td>\n      <td>0.392676</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.01000</td>\n      <td>0.0001</td>\n      <td>0.000005</td>\n      <td>60.0</td>\n      <td>0.784743</td>\n      <td>0.023349</td>\n      <td>0.008752</td>\n      <td>0.558071</td>\n      <td>0.039021</td>\n      <td>0.111226</td>\n      <td>0.507678</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>50.0</td>\n      <td>0.784853</td>\n      <td>0.002009</td>\n      <td>0.013279</td>\n      <td>0.557835</td>\n      <td>0.052967</td>\n      <td>0.140649</td>\n      <td>0.636591</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000001</td>\n      <td>60.0</td>\n      <td>0.770702</td>\n      <td>0.004789</td>\n      <td>0.005253</td>\n      <td>0.528576</td>\n      <td>0.023071</td>\n      <td>0.086059</td>\n      <td>0.382939</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>40.0</td>\n      <td>0.267772</td>\n      <td>0.017547</td>\n      <td>0.011452</td>\n      <td>0.515207</td>\n      <td>0.054302</td>\n      <td>0.097311</td>\n      <td>0.411967</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>50.0</td>\n      <td>0.762852</td>\n      <td>0.067204</td>\n      <td>0.014350</td>\n      <td>0.512741</td>\n      <td>0.012477</td>\n      <td>0.074704</td>\n      <td>0.330868</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.000100</td>\n      <td>60.0</td>\n      <td>0.758762</td>\n      <td>0.024889</td>\n      <td>0.002185</td>\n      <td>0.503865</td>\n      <td>0.005731</td>\n      <td>0.020442</td>\n      <td>0.087996</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>50.0</td>\n      <td>0.244555</td>\n      <td>0.000845</td>\n      <td>0.000804</td>\n      <td>0.500950</td>\n      <td>0.003470</td>\n      <td>0.042054</td>\n      <td>0.184902</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>0.10000</td>\n      <td>0.0001</td>\n      <td>0.001000</td>\n      <td>60.0</td>\n      <td>0.243118</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.077001</td>\n      <td>0.334925</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "result.sort_values(by='test bal-acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit48aa32fa6dba4f1bbd692e320b15fd93",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}